---
affiliation:
- id: 0
  organization: UCL
- id: 1
  organization: Warwick Business School
article:
  elocation-id: evalsumheterogenity
author:
- Valentin Klotzbücher
- Alberto Prati
- Caspar Kaiser
bibliography: /tmp/tmp-60ofRGBD75vXdj.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: "Evaluation Summary and Metrics: \"Adjusting for Scale-Use
  Heterogeneity in Self-Reported Well-Being\""
uri: "https://unjournal.pubpub.org/pub/evalsumheterogenity"
---

# Abstract 

We organized two evaluations of the paper: \"Adjusting for Scale-Use
Heterogeneity in Self-Reported Well-Being\" [@nr4c1ttzxp5]. To read
these evaluations, please see the links below.

## **Manager's note (**24 Nov 2025)

The authors have made it clear that this is an interim version of the
paper, and updates are forthcoming. We chose to evaluate it anyways
because of its prominence, relevance to ongoing practice, and link to
our [Pivotal Question project questions on the WELLBY
measure](https://coda.io/d/The-Unjournal-Hub-internal_d0KBG3dSZCs/Wellbeing-PQs_sumu-thA?utm_source=slack&utm_content=comment_notification#Specific-Wellbeing-PQs-and-Metaculus-questions-13-Nov-2025-WIP-u_tuyGzrVT/r75&columnId=c-AOhZtm8qbM "null").
Both evaluators were aware of this, and Prati's report explicitly
considered the updates presented in [recent
seminars](https://www.youtube.com/watch?v=RXXoCrmQhHE "null"). We
consider this an 'interim' evaluation, and we aim to follow this up with
further evaluations/updates when the revised paper is released.

## **Evaluations**

1\. [Caspar
Kaiser](https://unjournal.pubpub.org/pub/e1heterogenity/draft?access=apyc3edk "null")

2\. [Alberto
Prati](https://unjournal.pubpub.org/pub/e2heterogenity/draft?access=a3fwelxg "null")

# **Overall ratings**

We asked evaluators to provide overall assessments as well as ratings
for a range of specific criteria. * *

**I. Overall assessment **(See footnote[^1])

**II. Journal rank tier, normative rating (0-5): **On a 'scale of
journals', what 'quality of journal' should this be published in?[^2]
*Note: 0= lowest/none, 5= highest/best. *

+---+-------------------+---+
|   | **Overall         | * |
|   | assessment        | * |
|   | (0-100)**         | J |
|   |                   | o |
|   |                   | u |
|   |                   | r |
|   |                   | n |
|   |                   | a |
|   |                   | l |
|   |                   | r |
|   |                   | a |
|   |                   | n |
|   |                   | k |
|   |                   | t |
|   |                   | i |
|   |                   | e |
|   |                   | r |
|   |                   | , |
|   |                   | n |
|   |                   | o |
|   |                   | r |
|   |                   | m |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | v |
|   |                   | e |
|   |                   | r |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | n |
|   |                   | g |
|   |                   | ( |
|   |                   | 0 |
|   |                   | - |
|   |                   | 5 |
|   |                   | ) |
|   |                   | * |
|   |                   | * |
+===+===================+===+
| C | 67                | 3 |
| a |                   | . |
| s |                   | 5 |
| p |                   |   |
| a |                   |   |
| r |                   |   |
| K |                   |   |
| a |                   |   |
| i |                   |   |
| s |                   |   |
| e |                   |   |
| r |                   |   |
+---+-------------------+---+
| A | 95                | 5 |
| l |                   | . |
| b |                   | 0 |
| e |                   |   |
| r |                   |   |
| t |                   |   |
| o |                   |   |
| P |                   |   |
| r |                   |   |
| a |                   |   |
| t |                   |   |
| i |                   |   |
+---+-------------------+---+

*See
"*[*Metrics*](https://unjournal.pubpub.org/pub/evalsumheterogenity#metrics "null")*"
below for a more detailed breakdown of the evaluators' ratings across
several categories. To see these ratings in the context of all Unjournal
ratings, with some analysis, see our *[*data presentation
here.*](https://unjournal.github.io/unjournaldata/chapters/evaluation_data_analysis.html#basic-presentation "null")[^3]*
*

*See
*[*here*](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#metrics-overall-assessment-categories "null")*
for the current full evaluator guidelines, including further explanation
of the requested ratings.*

# Evaluation summaries

## Caspar Kaiser

This is a major methodological innovation in how we can adjust for
differences in scale-use. The empirical component would especially
benefit from more diverse and reliable samples.

## Alberto Prati

This is an extraordinary paper. It approaches a fundamental issue in
wellbeing measurement, and does so constructively, by suggesting and
testing a potential solution.

# Metrics

## Ratings

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#quantitative-metrics "null")
for details on the categories below, and the guidance given to
evaluators.

+---------------------------+--------------+--------+----------+--------------+--------+----------+
|                           | **Evaluator  |        |          | **Evaluator  |        |          |
|                           | 1**          |        |          | 2**          |        |          |
|                           |              |        |          |              |        |          |
|                           | Caspar       |        |          | Alberto      |        |          |
|                           | Kaiser       |        |          | Prati        |        |          |
+===========================+==============+========+==========+==============+========+==========+
| **Rating category**       | **Rating     | **90%  | **       | **Rating     | **90%  | **Co     |
|                           | (0-100)**    | CI **  | Comments | (0-100)**    | CI **  | mments** |
|                           |              |        | **       |              |        |          |
|                           |              | **(0-  |          |              | **(0-  |          |
|                           |              | 100)\* |          |              | 100)\* |          |
|                           |              | **     |          |              | **     |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Overall assessment[^4]    | 95           | (80,   | [^5]     | 95           | (90,   | [^6]     |
|                           |              | 100)   |          |              | 100)   |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Claims, strength,         | 80           | (70,   |          | 95           | (90,   |          |
| characterization of       |              | 90)    |          |              | 100)   |          |
| evidence[^7]              |              |        |          |              |        |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Advancing knowledge and   | 90           | (80,   | [^9]     | 95           | (90,   |          |
| practice[^8]              |              | 100)   |          |              | 100)   |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Methods: Justification,   | 90           | (80,   |          | 95\          | (90,   |          |
| reasonableness, validity, |              | 100)   |          |              | 100)   |          |
| robustness[^10]           |              |        |          |              |        |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Logic &                   | 75           | (60,   | [^12]    | 95           | (89,   |          |
| communication[^11]        |              | 90)    |          |              | 100)   |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Open, collaborative,      | 85           | (70,   | [^14]    | 95           | (90,   | [^15]    |
| replicable[^13]           |              | 90)    |          |              | 100)   |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Real-world relevance      | N/A          | N/A    | [^18]    | 86           | (74,   |          |
| [^16],[^17]               |              |        |          |              | 95)    |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+
| Relevance to global       | N/A          | N/A    |          | 86           | (74,   |          |
| priorities[^19], [^20]    |              |        |          |              | 95)    |          |
+---------------------------+--------------+--------+----------+--------------+--------+----------+

## Journal ranking tiers

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null")
for more details on these tiers.

+-------------------------------+-------------+---------------+------------+---------------+
|                               | **Evaluator |               | *          |               |
|                               | 1**         |               | *Evaluator |               |
|                               |             |               | 2**        |               |
|                               | Caspar      |               |            |               |
|                               | Kaiser      |               | Alberto    |               |
|                               |             |               | Prati      |               |
+===============================+=============+===============+============+===============+
| **Judgment**                  | **Ranking   | **90% CI **   | **Ranking  | **90% CI **   |
|                               | tier        |               | tier       |               |
|                               | (0-5)**     |               | (0-5)**    |               |
+-------------------------------+-------------+---------------+------------+---------------+
| On a 'scale of journals',     | 4.7         | (4.1, 5.0)    | 5.0        | (5.0, 5.0)    |
| what 'quality of journal'     |             |               |            |               |
| *should* this be published    |             |               |            |               |
| in?                           |             |               |            |               |
+-------------------------------+-------------+---------------+------------+---------------+
| What 'quality journal' do you | 4.4         | (4.0, 5.0)    | 4.8        | (4.5, 5.0)    |
| expect this work *will* be    |             |               |            |               |
| published in?                 |             |               |            |               |
+-------------------------------+-------------+---------------+------------+---------------+
| [See                          | *We         |               |            |               |
| here](https://                | summarize   |               |            |               |
| globalimpact.gitbook.io/the-u | these as:*  |               |            |               |
| njournal-project-and-communic |             |               |            |               |
| ation-space/policies-projects | -   0.0:    |               |            |               |
| -evaluation-workflow/evaluati |             |               |            |               |
| on/guidelines-for-evaluators# |  Marginally |               |            |               |
| journal-ranking-tiers "null") |     respect |               |            |               |
| for more details on these     | able/Little |               |            |               |
| tiers.                        |     to no   |               |            |               |
|                               |     value   |               |            |               |
|                               |             |               |            |               |
|                               | -   1.0:    |               |            |               |
|                               |             |               |            |               |
|                               | OK/Somewhat |               |            |               |
|                               |             |               |            |               |
|                               |    valuable |               |            |               |
|                               |             |               |            |               |
|                               | -   2.0:    |               |            |               |
|                               |             |               |            |               |
|                               |    Marginal |               |            |               |
|                               |     B-jou   |               |            |               |
|                               | rnal/Decent |               |            |               |
|                               |     field   |               |            |               |
|                               |     journal |               |            |               |
|                               |             |               |            |               |
|                               | -   3.0:    |               |            |               |
|                               |     Top     |               |            |               |
|                               |     B-jou   |               |            |               |
|                               | rnal/Strong |               |            |               |
|                               |     field   |               |            |               |
|                               |     journal |               |            |               |
|                               |             |               |            |               |
|                               | -   4.0:    |               |            |               |
|                               |             |               |            |               |
|                               |    Marginal |               |            |               |
|                               |     A-      |               |            |               |
|                               | Journal/Top |               |            |               |
|                               |     field   |               |            |               |
|                               |     journal |               |            |               |
|                               |             |               |            |               |
|                               | -   5.0:    |               |            |               |
|                               |     A-      |               |            |               |
|                               | journal/Top |               |            |               |
|                               |     journal |               |            |               |
+-------------------------------+-------------+---------------+------------+---------------+

# Claim identification and assessment (summary)

For *the full discussions, see the* *corresponding sections in each
linked evaluation.*

+---------------+--------------------------------+---------------------+-----------------------------+
|               | **Main research claim**[^21]   | **Belief in         | **Suggested robustness      |
|               |                                | claim**[^22]        | checks**[^23]               |
+===============+================================+=====================+=============================+
| **Evaluator 1 | There is new method to adjust  | There certainly is  | N/A \[But see suggestions   |
| **\           | for scale-use differences      | a new method. I     | in report.\]                |
| Caspar Kaiser | which can be implemented both  | would be interested |                             |
|               | with existing data containing  | in seeing           |                             |
|               | vignettes, and with new data   | comparisons with    |                             |
|               | that require only few          | existing methods.   |                             |
|               | additional questions.          |                     |                             |
+---------------+--------------------------------+---------------------+-----------------------------+
| **Evaluator 2 | The authors develop an         | N/A                 | From the current WP, it is  |
| **\           | innovative framework to model  |                     | not entirely clear how good |
| Alberto Prati | and adjust for scale           |                     | the correction performs     |
|               | heterogeneity, they test it    |                     | when only two CQ are used   |
|               | using some new calibration     |                     | and when short SWB scales   |
|               | questions and show that their  |                     | are used.                   |
|               | adjustment can lead to         |                     |                             |
|               | different results in some      |                     |                             |
|               | applications.                  |                     |                             |
+---------------+--------------------------------+---------------------+-----------------------------+

## References

[@n76dpsilo1i] Daniel J. Benjamin, Kristen Cooper, Ori Heffetz, Miles S.
Kimball, and Jiannan Zhou, \"Adjusting for Scale-Use Heterogeneity in
Self-Reported Well-Being,\" NBER Working Paper 31728 (2023),
https://doi.org/10.3386/w31728.

# Evaluation manager's discussion (optional)[^24]

*\[To be added after the authors' potential response\]*

## Issues meriting further evaluation[^25]

# Unjournal process notes (\~optional)[^26] 

***Note on versions:***

Casper Kaiser's evaluation was based on the version of the paper updated
on NBER in December 2023
([here](https://www.nber.org/papers/w31728 "null")). Alberto Prati's
evaluation was based on this as well as "the forthcoming version of the
study which was presented at the Oxford Wellbeing Research Centre six
months ago" (linked
[video](https://www.youtube.com/watch?v=RXXoCrmQhHE "null")).

## Why we chose this paper 

This paper seemed both prominent and relevant to our [Pivotal Questions
project](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/pivotal-questions-initiative#the-pivotal-questions-project-in-brief "null"),
in discussion with [Founders'
Pledge](https://www.founderspledge.com/ "null"), addressing

-   Which metrics would be "best\*" for making funding choices between
    interventions whose impacts may include mental health, physical
    health, and consumption outcomes.

-   The usefulness of the linear WELLBY measure, and its
    comparability/conversion with other measures (like QALY)

and a further [set of operationalized
questions](https://coda.io/d/Unjournal-Public-Pages_ddIEzDONWdb/Wellbeing-PQ_suPg8sEH#_luVrD0mE. "null")

And, from our internal notes:

> Wellbeing is being \[used\] more and more as an ultimate outcome, and
> these methodological issues are first order.
>
> If scale-use heterogeneity materially changes the ranking of
> interventions, then results that ignore it may mis-allocate large
> pools of resources.
>
> The NBER working paper is already being cited; several groups are
> planning to use it.
>
> Relation to HLI report "A Happy Possibility About Happiness (And
> Other) Scales - Happier Lives Institute", discussed by organizations
> we are in contact with

## How we chose the evaluators

## Evaluation process

### COI issues

Casper Kaiser noted he has been in contact with the authors, but this
did not constitute a \"close or moderate personal or professional
connection\" according to our COI
[guidelines](https://docs.google.com/document/d/1pxhBPYrwzFA4BCpyQC0vwiUxZ6Zq-UAW60mi_GvYOBw/edit?tab=t.0#heading=h.ri8bve8d64rk "null").

[^1]: We asked them to rank this paper "heuristically" as a percentile
    "relative to all serious research in the same area that you have
    encountered in the last three years." We requested they "consider
    all aspects of quality, credibility, importance to knowledge
    production, and importance to practice.

[^2]: See ranking tiers discussed
    [here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers).

[^3]: Note: if you are reading this before, or soon after this has been
    publicly released, the ratings from this paper may not yet have been
    incorporated into that data presentation.

[^4]: Judge the quality of the research heuristically. Consider all
    aspects of quality, credibility, importance to knowledge production,
    and importance to practice.

[^5]: A LONG COMMENT ... Excellent as an overview, and important for
    global health, but unfortunately somewhat disappointing about ways
    to address global catastrophic risks 

    \
    \[*Editor's note: the evaluator has explained that they have not
    based their assessment on this point; we do not intend  \'Relevance
    to Global Priorities\" to factor into the overall assessment)*

[^6]: Ironically, the paper shows that this type of assessment will
    change from a reviewer to another\...!

[^7]: "Do the authors do a good job of (i) stating their main questions
    and claims, (ii) providing strong evidence and powerful approaches
    to inform these, and (iii) correctly characterizing the nature of
    their evidence?"\
    \
    This was on the newer form only

[^8]: To what extent does the project contribute to the field or to
    practice, particularly in ways that are directly or indirectly
    relevant to global priorities and impactful interventions?

[^9]: Again, these ratings are relative to field of subjective wellbeing
    research, not to work on global priorities in general.

[^10]: Are methods clearly justified and explained? Are methods and
    their underlying assumptions reasonable? Are the results likely to
    be robust to changes in the assumptions? Have the authors avoided
    bias and questionable research practices?

[^11]: Are concepts clearly defined? Is the reasoning transparent? Are
    conclusions consistent with the evidence (or formal proofs)
    presented? Are the data and/or analysis, including tables and
    figures, relevant to the argument?

[^12]: The reasoning itself, to the extent that I was able to assess it,
    was sound and very thorough. As noted in my review, the paper itself
    could have been more accessible.

[^13]: Would another researcher be able to replicate the analysis? Are
    the method and its details explained sufficiently? Is the source of
    the data clear? Is the data made as widely available as possible,
    with clear labeling and explanation? Do the authors provide
    resources that are likely to enable future research and
    meta-analysis?

[^14]: The authors have shared the data. I was able to replicate the
    simplest version of their method using Stata (they were using R). I
    have not attempted to fully replicate the paper, so cannot comment
    on this.

[^15]: I don\'t think the replication files are available yet,  but this
    publication is a work in progress.

[^16]: Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic and relevant to practitioners?

[^17]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^18]: I left this open because it seems hard to assess. In my mind this
    is a paper about a fundamental scientific question, which will
    eventually be of relevance to (policy) practitioners. However, the
    paper, at present, is not aimed at that.

[^19]: Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?

[^20]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^21]: The evaluator was given the following instructions:\
    \
    Identify the most important and impactful factual claim this
    research makes -- e.g., a binary claim or a point estimate or
    prediction.

    Please state the authors' claim precisely and quantitatively.
    Identify the source of the claim (i.e., cite the paper), and briefly
    mention the evidence underlying this. We encourage you to explain
    why you believe this claim is important, either here, or in the text
    of your report.

[^22]: Evaluators were asked: To what extent do you \*believe\* the
    claim you stated above? Feel free to express this either a. in terms
    of the probability of the claim being true, b. as a credible
    interval for the parameter being estimated, or c. however you feel
    comfortable.

[^23]: *We asked:*

    \[Optional\] What additional information, evidence, replication, or
    robustness check would make you substantially more (or less)
    confident in this claim?

    Feel free to refer to the main body of your evaluation here; you
    don\'t need to repeat yourself. Please specify how you would perform
    this robustness check (etc.) as precisely as you are willing. E.g.,
    if you suggest a particular estimation command in a statistical
    package, this could be very helpful for future robustness
    replication work.

[^24]: Evaluation managers: After the evaluations and author responses
    are in, you may want to give a brief synthesis and reflection on the
    research, the evaluations, and the response, considering the
    implications of these, future directions, etc. You can insert your
    own judgment here, if you like.

[^25]: Evaluation managers: Use this section to list or explain issues
    that need further scrutiny, potentially by ["independent Unjournal
    evaluators"](https://coda.io/d/_d0KBG3dSZCs/Crowdsourcing-independent-evaluations_sufF1).
    These may be issues you suggested in your "manager's notes"/"bespoke
    evaluation notes" or issues evaluators identified that they
    acknowledged they were not fully able to address.

[^26]: Evaluation managers: We usually put a brief discussion of why we
    prioritized this work and the evaluation process here. Please try to
    keep this concise: avoid boilerplate, profuse gratitude or flattery.
    There is no need to report on the parts of this process that worked
    normally.
